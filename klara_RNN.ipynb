{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of load_steinmetz_decisions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klaragerlei/GoatsOfAllTime/blob/main/klara_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqdz1ZUMaj1"
      },
      "source": [
        "## Loading of Steinmetz data\n",
        "\n",
        "includes some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWjKq8bLDqm",
        "cellView": "form"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raBVOEWgUK_B",
        "cellView": "form"
      },
      "source": [
        "#@title Import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sffzC_hyLgWZ"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7UT7dyj_6R"
      },
      "source": [
        "`alldat` contains 39 sessions from 10 mice, data from Steinmetz et al, 2019. Time bins for all measurements are 10ms, starting 500ms before stimulus onset. The mouse had to determine which side has the highest contrast. For each `dat = alldat[k]`, you have the fields below. For extra variables, check out the extra notebook and extra data files (lfp, waveforms and exact spike times, non-binned). \n",
        "\n",
        "* `dat['mouse_name']`: mouse name\n",
        "* `dat['date_exp']`: when a session was performed\n",
        "* `dat['spks']`: neurons by trials by time bins.    \n",
        "* `dat['brain_area']`: brain area for each neuron recorded. \n",
        "* `dat['ccf']`: Allen Institute brain atlas coordinates for each neuron. \n",
        "* `dat['ccf_axes']`: axes names for the Allen CCF. \n",
        "* `dat['contrast_right']`: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "* `dat['contrast_left']`: contrast level for left stimulus. \n",
        "* `dat['gocue']`: when the go cue sound was played. \n",
        "* `dat['response_time']`: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and nearly always does!), but the stimulus on the screen won't move before the go cue.  \n",
        "* `dat['response']`: which side the response was (`-1`, `0`, `1`). When the right-side stimulus had higher contrast, the correct choice was `-1`. `0` is a no go response. \n",
        "* `dat['feedback_time']`: when feedback was provided. \n",
        "* `dat['feedback_type']`: if the feedback was positive (`+1`, reward) or negative (`-1`, white noise burst).  \n",
        "* `dat['wheel']`: turning speed of the wheel that the mice uses to make a response, sampled at `10ms`. \n",
        "* `dat['pupil']`: pupil area  (noisy, because pupil is very small) + pupil horizontal and vertical position.\n",
        "* `dat['face']`: average face motion energy from a video camera. \n",
        "* `dat['licks']`: lick detections, 0 or 1.   \n",
        "* `dat['trough_to_peak']`: measures the width of the action potential waveform for each neuron. Widths `<=10` samples are \"putative fast spiking neurons\". \n",
        "* `dat['%X%_passive']`: same as above for `X` = {`spks`, `pupil`, `wheel`, `contrast_left`, `contrast_right`} but for  passive trials at the end of the recording when the mouse was no longer engaged and stopped making responses. \n",
        "* `dat['prev_reward']`: time of the feedback (reward/white noise) on the previous trial in relation to the current stimulus time. \n",
        "* `dat['reaction_time']`: ntrials by 2. First column: reaction time computed from the wheel movement as the first sample above `5` ticks/10ms bin. Second column: direction of the wheel movement (`0` = no move detected).  \n",
        "\n",
        "\n",
        "The original dataset is here: https://figshare.com/articles/dataset/Dataset_from_Steinmetz_et_al_2019/9598406"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpE8gVVt38DI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f214fcdd-4adc-443a-9469-96d52a834c7d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!git clone https://github.com/klaragerlei/GoatsOfAllTime.git\n",
        "import GoatsOfAllTime.data_loader as dl\n",
        "\n",
        "data_to_analyze = dl.load_data(alldat)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GoatsOfAllTime' already exists and is not an empty directory.\n",
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0OVagbSC8O"
      },
      "source": [
        "def change_bin_size(array_in, window_size=10):\n",
        "  array_with_different_bins = np.add.reduceat(array_in, range(0, len(array_in), window_size))\n",
        "  return array_with_different_bins\n",
        "\n",
        "#test_array = np.array([0, 1, 0, 0, 1, 0,3, 4, 5, 4, 1, 2, 3, 4, 5, 5, 0])\n",
        "#print(test_array.shape)\n",
        "#array_out = change_bin_size(test_array, window_size=10)\n",
        "#print(test_array)\n",
        "#print(array_out)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp_WwQMBWgmp",
        "outputId": "2b14be0a-77b9-415c-9d08-e9c0e4dfb3ab"
      },
      "source": [
        "def convert_data_to_bigger_bin_size_spikes(data_to_analyze):\n",
        "  spikes_big_bins = []\n",
        "  for session_id, session in data_to_analyze.iterrows():\n",
        "    spikes_in_session = []\n",
        "    spikes = session.spikes\n",
        "    for neuron in range(spikes.shape[0]):\n",
        "      spikes_from_neuron = []\n",
        "      spikes_neuron = spikes[neuron]\n",
        "      spikes_all_trials = np.array(spikes_neuron.reshape(-1))\n",
        "      spikes_new_bin_size = change_bin_size(spikes_all_trials, window_size=10)\n",
        "      spikes_in_session.append(spikes_new_bin_size)\n",
        "    spikes_big_bins.append(spikes_in_session)\n",
        "  data_to_analyze['spikes_bigger_bins'] = spikes_big_bins\n",
        "  print(data_to_analyze.spikes_bigger_bins)\n",
        "  return data_to_analyze\n",
        "\n",
        "data_to_analyze = convert_data_to_bigger_bin_size_spikes(data_to_analyze)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
            "20    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...\n",
            "28    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
            "Name: spikes_bigger_bins, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw5nxqbLqE0k"
      },
      "source": [
        "def convert_data_to_bigger_bin_size_face(data_to_analyze):\n",
        "  face_data = []\n",
        "  for session_id, session in data_to_analyze.iterrows():\n",
        "    face_in_session = session.face\n",
        "    face_data_flat = face_in_session.reshape(-1)\n",
        "    face_new_bin_size = change_bin_size(face_data_flat, window_size=10)\n",
        "    face_data.append(face_new_bin_size)\n",
        "  data_to_analyze['face_bigger_bins'] = face_data\n",
        "  return data_to_analyze\n",
        "\n",
        "data_to_analyze = convert_data_to_bigger_bin_size_face(data_to_analyze)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbBZYK6rfPyK"
      },
      "source": [
        "def add_number_of_spikes_per_neuron_to_df(df):\n",
        "  number_of_spikes = []\n",
        "  for recording_index, recording in df.iterrows():\n",
        "    spikes_all = recording.spikes\n",
        "    spikes_neuron = []\n",
        "    for neuron in range(spikes_all.shape[0]):\n",
        "      num_of_spikes = np.sum(spikes_all[neuron])\n",
        "      spikes_neuron.append(num_of_spikes)\n",
        "    number_of_spikes.append(spikes_neuron)\n",
        "  df['number_of_spikes'] = number_of_spikes\n",
        "  return df      \n",
        "\n",
        "data_to_analyze = add_number_of_spikes_per_neuron_to_df(data_to_analyze)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HG1kS35j0ln"
      },
      "source": [
        "# plot spikes across time\n",
        "def plot_spikes_across_time():\n",
        "  session_id = 0\n",
        "  neuron_id = 10\n",
        "  # spikes_of_neuron = data_to_analyze.spikes[session_id][neuron_id]\n",
        "\n",
        "  session_to_analyze = data_to_analyze.spikes.iloc[session_id]\n",
        "  number_of_spikes = data_to_analyze.number_of_spikes.iloc[session_id][neuron_id]\n",
        "  print('Number of spikes: ' + str(number_of_spikes))\n",
        "  spikes_of_neuron = session_to_analyze.reshape(session_to_analyze.shape[0], -1)[neuron_id]\n",
        "  plt.figure()\n",
        "  plt.plot(spikes_of_neuron)\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgc-nMSulgPv"
      },
      "source": [
        "# plot pupil size\n",
        "def plot_pupil_size():\n",
        "  print(data_to_analyze.iloc[session_id].pupil.shape)\n",
        "  pupil_data_to_plot_1 = data_to_analyze.pupil.iloc[session_id][1].T[0]\n",
        "  pupil_data_to_plot_2 = data_to_analyze.pupil.iloc[session_id][2].T[0]\n",
        "  print(pupil_data_to_plot.shape)\n",
        "  plt.figure()\n",
        "  plt.plot(pupil_data_to_plot_1)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  plt.figure()\n",
        "  plt.plot(pupil_data_to_plot_2)\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv19hm-xO01o"
      },
      "source": [
        "def reshape_pupil_data():\n",
        "  # Make input features for model\n",
        "  session_id = 0   # we will analyze this session\n",
        "  session_to_analyze = data_to_analyze.spikes.iloc[session_id]\n",
        "  print('number of spikes')\n",
        "  print(data_to_analyze.number_of_spikes.iloc[session_id])\n",
        "  print('Number of neurons in this session: ' + str(session_to_analyze.shape[0]))\n",
        "  # try only one trial\n",
        "  trial_id = 2\n",
        "  session_to_analyze_reshaped = session_to_analyze[:,trial_id,:] # first trial \n",
        "  pupil_data = data_to_analyze.pupil.iloc[0][0,trial_id]  # first trial \n",
        "\n",
        "  print(session_to_analyze_reshaped.shape)\n",
        "  print(pupil_data.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52NWZlr-P7vB",
        "outputId": "99bb952e-5f90-4d1d-c87f-4a410cd2cd37"
      },
      "source": [
        "  def reshape_face_data(data_to_analyze, session_id=0, trial_id=None):\n",
        "    # Make input features for model\n",
        "    session_to_analyze = data_to_analyze.spikes.iloc[session_id]\n",
        "    print('number of spikes')\n",
        "    print(data_to_analyze.number_of_spikes.iloc[session_id])\n",
        "    print('Number of neurons in this session: ' + str(session_to_analyze.shape[0]))\n",
        "\n",
        "    session_to_analyze_reshaped = session_to_analyze[-1] # all trials \n",
        "    face_data = data_to_analyze.face.iloc[session_id][0,-1]  # all trials\n",
        "\n",
        "    if trial_id != None:\n",
        "      session_to_analyze_reshaped = session_to_analyze[:,trial_id,:] # one trial \n",
        "      face_data = data_to_analyze.face.iloc[session_id][0,trial_id]  # one trial \n",
        "\n",
        "\n",
        "    print(session_to_analyze_reshaped.shape)\n",
        "    print(face_data.shape)\n",
        "    return face_data, session_to_analyze_reshaped\n",
        "behaviour_data, session_to_analyze_reshaped = reshape_face_data(data_to_analyze, trial_id=None)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of spikes\n",
            "[4, 1784, 391, 8565, 204, 34, 4777, 301, 64, 5462, 0, 3077, 50, 51, 509, 2135, 141, 64, 5977, 5520, 484, 1822, 9, 79, 0, 287, 556, 41, 100, 14010, 114, 148, 174, 113, 1307, 5292, 147, 1849, 403, 691, 251, 5487, 93, 48, 2263, 59, 76, 100, 10227, 119, 454, 1676, 14, 253, 127, 1110, 1678, 1570, 130, 1812, 200, 117, 126, 7273, 129, 5138, 80, 301, 321, 24, 3637, 21, 5651, 4862, 28, 50, 723, 836, 1071, 50, 5002, 713, 35, 0, 187, 185, 2214, 11, 241, 1630, 2840, 275, 729, 2881, 185, 599, 136, 745, 14723, 217, 11110, 730, 267, 72, 130, 1636, 3669, 140, 1892, 118, 107, 41, 76, 8279, 895, 966, 68, 234, 80, 5509, 287, 6506, 7983, 303, 35, 137, 51, 41, 1265, 143, 180, 309, 1643, 287, 21338, 28892, 16645, 13582, 5876, 15118, 15296, 6715, 4707, 8655, 7542, 6413, 5596, 119, 10387, 5268, 2304, 1554, 1347, 3554, 9785, 140, 1719, 310, 23, 311, 607, 1657, 481, 17437, 1053, 43, 4900, 400, 1345, 6340, 44, 2809, 547, 440, 1845, 75, 1675, 2696, 1114, 321, 2708, 5707, 1953, 2710, 455, 873, 521, 248, 120, 4034, 101, 611, 330, 389, 1261, 1654, 379, 933, 616, 539, 174, 359, 284, 1106, 566, 929, 419, 107, 499, 752, 445, 314, 1482, 424, 1259, 2269, 508, 2189, 542, 1405, 61, 188, 449, 1077, 68, 937, 164, 570, 239, 844, 592, 3415, 389, 317, 468, 3150, 173, 955, 5999, 107, 199, 269, 89, 460, 286, 301, 1004, 957, 124, 492, 393, 22517, 920, 758, 1273, 401, 319, 11034, 7766, 11869, 1959, 8, 2380, 289, 0, 21207, 13857, 23154, 18301, 9967, 11768, 3590, 9186, 11604, 7814, 5830, 3930, 4727, 2168, 3190, 1608, 1483, 2669, 2635, 484, 15182, 716, 132, 319, 1697, 1188, 921, 738, 518, 177, 6269, 182, 593, 1475, 150, 2349, 15390, 1991, 81, 442, 1, 4, 5744, 1071, 5125, 2659, 1022, 2371, 2235, 4348, 1771, 520, 444, 672, 2, 8870, 1110, 69, 29221, 1253, 2752, 4344, 1295, 13626, 163, 5072, 350, 3538, 3424, 382, 203, 3714, 1052, 5337, 23, 190, 408, 470, 285, 620, 4732, 35, 326, 509, 11784, 2512, 6705, 146, 8, 3190, 4777, 37, 330, 69, 0, 2922, 993, 567, 570, 91, 711, 1707, 12, 850, 4743, 727, 1210, 1732, 389, 2792, 185, 2422, 3289, 2305, 93, 6, 59, 255, 8688, 7, 6692, 8638, 1620, 505, 1242, 490, 13897, 2033, 2015, 66, 1024, 719, 4069, 5635, 5221, 4043, 745, 1616, 3637, 5642, 83, 368, 5, 1439, 1064, 3, 111, 2698, 188, 1043, 1949, 238, 5372, 31, 2316, 1980, 55, 5089, 4706, 165, 1300, 846, 3232, 318, 12026, 5817, 23845, 17990, 31826, 57986, 19682, 17692, 16327, 11519, 10280, 18216, 13051, 5900, 5359, 8577, 7159, 7604]\n",
            "Number of neurons in this session: 447\n",
            "(342, 250)\n",
            "(250,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvuYenypojcc"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn2Azr-KpR56"
      },
      "source": [
        "Define network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ksH0Qlto3t3"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, ncomp, NN1, NN2, bidi=True):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # play with some of the options in the RNN!\n",
        "    self.rnn = nn.RNN(NN1, ncomp, num_layers = 1, dropout = 0,\n",
        "                      bidirectional = bidi, nonlinearity = 'tanh')\n",
        "    self.fc = nn.Linear(ncomp, NN2)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    y = self.rnn(x)[0]\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
        "      # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
        "      q = (y[:, :, :ncomp] + y[:, :, ncomp:])/2\n",
        "    else:\n",
        "      q = y\n",
        "\n",
        "    # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
        "    # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
        "    z = F.softplus(self.fc(q), 10)\n",
        "\n",
        "    return z, q"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAqfK3-RpPTl"
      },
      "source": [
        "Prepare input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "0rfgR5Exo9-O",
        "outputId": "413db715-4c32-4961-fe70-22a4fa819522"
      },
      "source": [
        "# todo x0 should be the spikes and x1 the behaviour\n",
        "x0 = torch.from_numpy(x[:, :, :200]).to(device).float()\n",
        "x1 = torch.from_numpy(x[:, :, 200:]).to(device).float()\n",
        "\n",
        "#x0 = torch.from_numpy(session_to_analyze_reshaped.T).to(device).float()\n",
        "# change this to be a different bit of the data\n",
        "#x0 = torch.from_numpy(session_to_analyze_reshaped.T).to(device).float()\n",
        "# x1 = torch.from_numpy(behaviour_data).to(device).float()\n",
        "\n",
        "\n",
        "NN1 = x1.shape[-1]\n",
        "NN2 = x0.shape[-1]\n",
        "\n",
        "# let's use 10 latent components\n",
        "ncomp = 10\n",
        "\n",
        "# we initialize the neural network\n",
        "net = Net(ncomp, NN1, NN2, bidi = True).to(device)\n",
        "\n",
        "# special thing:  we initialize the biases of the last layer in the neural network\n",
        "# we set them as the mean firing rates of the neurons.\n",
        "# this should make the initial predictions close to the mean, because the latents don't contribute much\n",
        "net.fc.bias.data[:] = x1.mean((0,1))  # !!!!!!!!!!!\n",
        "\n",
        "# we set up the optimizer. Adjust the learning rate if the training is slow or if it explodes.\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=.005)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9d6130e1f15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# todo x0 should be the spikes and x1 the behaviour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#x0 = torch.from_numpy(session_to_analyze_reshaped.T).to(device).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXUOhjSlpVn_"
      },
      "source": [
        "Train network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "5xzV89xVpOFW",
        "outputId": "49fbaf19-9797-4c1b-c773-7ca11bfe8485"
      },
      "source": [
        "# you can keep re-running this cell if you think the cost might decrease further\n",
        "\n",
        "# we define the Poisson log-likelihood loss\n",
        "def Poisson_loss(lam, spk):\n",
        "  return lam - spk * torch.log(lam)\n",
        "\n",
        "niter = 1000\n",
        "for k in range(niter):\n",
        "  # the network outputs the single-neuron prediction and the latents\n",
        "  z, y = net(x1)\n",
        "\n",
        "  # our log-likelihood cost\n",
        "  cost = Poisson_loss(z, x0).mean()\n",
        "\n",
        "  # train the network as usual\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if k % 100 == 0:\n",
        "    print(f'iteration {k}, cost {cost.item():.4f}')\n",
        "  \n",
        "\n",
        "  rpred = z.detach().cpu().numpy()  # predicted output"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3ad56ba626ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# the network outputs the single-neuron prediction and the latents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# our log-likelihood cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0b8b6b37ed94>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    }
  ]
}